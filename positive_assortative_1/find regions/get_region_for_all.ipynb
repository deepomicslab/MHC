{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "from pysam import VariantFile as vcf\n",
    "import operator\n",
    "from math import log2\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scipy\n",
    "import  os\n",
    "import os.path\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAveragePer1000(filepath,n,filename):\n",
    "    csv_data = pd.read_csv(filepath, low_memory = False)\n",
    "    csv_df = pd.DataFrame(csv_data)\n",
    "    averages = [np.mean(csv_df.loc[i:i+n-1, \"P\"]) for i in range(0, csv_df.shape[0], n)]\n",
    "    np.savetxt('../../similar_region_average1000/'+filename+'.csv', averages, delimiter = ',')\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrforDistribution=[]\n",
    "for curDir, dirs, files in os.walk(top=\"../../similar_region_csvfiles/\"):\n",
    "    for file in files:\n",
    "        if file.startswith(\"pos_prob_split_\"):\n",
    "            fileprefix=file[file.index(\"chr\"):file.index(\".\")]\n",
    "            filepath=os.path.join(curDir,file)\n",
    "            arrforDistribution+=getAveragePer1000(filepath=filepath,n=1000,filename=fileprefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean of Distribution\n",
    "mean_arr=np.mean(arrforDistribution)\n",
    "#get standard deviation of Distribution\n",
    "std_arr=np.std(arrforDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareWith0_01Pvalue(mean_arr,std_arr,filename,filepath):\n",
    "    arr=[]\n",
    "    csv_matrix = np.loadtxt(open(filepath,\"rb\"),delimiter=\",\",skiprows=0)\n",
    "    for i in range(len(csv_matrix)):\n",
    "        mid_res=stats.norm.cdf(csv_matrix[i], mean_arr, std_arr)\n",
    "        if mid_res>0.95:\n",
    "            arr.append(1)\n",
    "        else:\n",
    "            arr.append(0)\n",
    "    np.savetxt(\"../../similar_region_95_compare/\"+filename+\".csv\", arr, delimiter = ',')\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curDir, dirs, files in os.walk(top=\"../../similar_region_average1000/\"):\n",
    "    for file in files:            \n",
    "        filename=file[:file.index(\".\")]\n",
    "        prefix=filename.split(\"_\")[0]\n",
    "        filepath=os.path.join(curDir,file)\n",
    "        #print(filepath)\n",
    "        compareWith0_01Pvalue(mean_arr=mean_arr,std_arr=std_arr,filename=filename,filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatedfandcsv(columns,dic,filename):\n",
    "\n",
    "    row_names=list(dic.keys())\n",
    "    a=[]\n",
    "    bs=[]\n",
    "    #cs=[]\n",
    "    for x in row_names:\n",
    "        a.append(x)\n",
    "        bs.append(dic[x])\n",
    "        #cs.append(dic[x][1])\n",
    "    dictforDF=dict()\n",
    "    dictforDF[columns[0]]=a\n",
    "    dictforDF[columns[1]]=bs\n",
    "    #dictforDF[columns[2]]=cs\n",
    "\n",
    "    df_index=pd.DataFrame(dictforDF)\n",
    "    df_index.to_csv(\"../../similar_region_95_start_length/\"+filename+\"_start_lenth.csv\")\n",
    "    return df_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkContinuous1(arr):\n",
    "    res=dict()\n",
    "    i=0\n",
    "    while i<len(arr)-1:\n",
    "\n",
    "        if arr[i]==1:\n",
    "\n",
    "            count=1\n",
    "            for j in range(i+1,len(arr),1):\n",
    "                if arr[j]==1:\n",
    "                    count+=1\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    break\n",
    "\n",
    "            res[i]=count\n",
    "            i+=count\n",
    "\n",
    "        else:\n",
    "            i+=1\n",
    "            continue\n",
    "    return res\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstartAndLength(filepath,filename):\n",
    "    csv_matrix = np.loadtxt(open(filepath,\"rb\"),delimiter=\",\",skiprows=0)\n",
    "    res=checkContinuous1(csv_matrix)\n",
    "    df=generatedfandcsv(columns=[\"start\",\"length\"],dic=res,filename=filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curDir, dirs, files in os.walk(top=\"../../similar_region_95_compare/\"):\n",
    "    for file in files:\n",
    "        filename=file[:file.index(\".\")]\n",
    "        filepath=os.path.join(curDir,file)\n",
    "        getstartAndLength(filepath=filepath,filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def countNumofLength(dic,filepath):\n",
    "    csv_data = pd.read_csv(filepath, low_memory = False)\n",
    "    csv_df = pd.DataFrame(csv_data)\n",
    "    arr=np.array(csv_df['length'])\n",
    "    #print(dic)\n",
    "    for i in range(len(arr)):\n",
    "        #print(\"before iteration\",dic)\n",
    "        if arr[i] in dic:\n",
    "            #print(\"in iteration not\",dic)\n",
    "            dic[arr[i]]+=1\n",
    "        else:\n",
    "            dic[arr[i]]=1\n",
    "            #print(\"in iteration\",dic)\n",
    "    #print(dic)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mydic=dict()\n",
    "mhcdic=dict()\n",
    "for curDir, dirs, files in os.walk(top=\"../../similar_region_95_start_length/\"):\n",
    "    for file in files:\n",
    "            filename=file[:file.index(\".\")]\n",
    "            if filename!=\"mhc_start_lenth\":                  \n",
    "                filepath=os.path.join(curDir,file)\n",
    "                countNumofLength(mydic,filepath=filepath)\n",
    "            else:\n",
    "                 filepath_mhc=os.path.join(curDir,file)\n",
    "                 countNumofLength(mhcdic,filepath=filepath_mhc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhcdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 318,\n",
       " 2: 99,\n",
       " 4: 29,\n",
       " 11: 3,\n",
       " 3: 61,\n",
       " 5: 12,\n",
       " 63: 1,\n",
       " 15: 1,\n",
       " 6: 8,\n",
       " 100: 1,\n",
       " 56: 1,\n",
       " 7: 7,\n",
       " 9: 1,\n",
       " 13: 2,\n",
       " 45: 1,\n",
       " 8: 6,\n",
       " 23: 1,\n",
       " 33: 1,\n",
       " 31: 1,\n",
       " 79: 1,\n",
       " 16: 1,\n",
       " 59: 1,\n",
       " 20: 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1=[]\n",
    "\n",
    "for k2,arr in mydic.items():\n",
    "    for i in range(arr):\n",
    "        arr1.append(k2)\n",
    "\n",
    "for k2,arr in mhcdic.items():\n",
    "    for i in range(arr):\n",
    "        arr1.append(k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 2.917562724014337\n",
      "dev 7.49984562389563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.62663735771988"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_1=np.mean(arr1)\n",
    "dev1=np.std(arr1)\n",
    "print(\"mean\",mean_1)\n",
    "print(\"dev\",dev1)\n",
    "mid_res=stats.norm.ppf(0.9999999999,mean_1,dev1)\n",
    "mid_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getAllPositions(filepath):\n",
    "    pos=[]\n",
    "    #vcf_in=vcf(filepath)\n",
    "    vcf_file = pysam.VariantFile(filepath)\n",
    "    for record in vcf_file:\n",
    "\n",
    "        pos.append(record.pos)\n",
    "    pos=sorted(list(set(pos)))\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPosition(filepath,start,length):\n",
    "    arr=[]\n",
    "    allpos=getAllPositions(filepath=filepath)\n",
    "    arr.append(allpos[start*1000])\n",
    "    if (start+length)*1000-1<len(allpos):\n",
    "        end=allpos[(start+length)*1000-1]\n",
    "    else:\n",
    "        end=allpos[-1]\n",
    "    arr.append(end)\n",
    "    return arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GetPosition(filepath,res,threshold):\n",
    "    csv_data = pd.read_csv(filepath, low_memory = False)\n",
    "    csv_df = pd.DataFrame(csv_data)\n",
    "    arr_start=np.array(csv_df['start'])\n",
    "    arr_length=np.array(csv_df['length'])\n",
    "    mydic=dict()\n",
    "    midarr=[]\n",
    "    for i in range(len(arr_start)):\n",
    "        mydic[arr_start[i]]=arr_length[i]\n",
    "    filename=(filepath.split(\"/\")[-1]).split(\"_start_lenth.csv\")[0]\n",
    "    findfoldername=\"split_\"+filename.split(\"_\")[0]\n",
    "    findfoldername_filename=filename.split(\"_\")[1].split(\".\")[0]\n",
    "    filepath=\"../../\"+findfoldername+\"/\"+findfoldername_filename+\".vcf.gz\"\n",
    "    for k,v in mydic.items():\n",
    "        if v>=threshold:\n",
    "            print(\"filepath\",filepath)\n",
    "            midarr.append(findPosition(filepath=filepath,start=k,length=v))\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "    if midarr!=[]:\n",
    "        res[findfoldername+\"_\"+findfoldername_filename]=midarr\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPositionforMHC(res):\n",
    "    mhc_start_length_path=\"/data2/wangxuedong/mhc_test_data/similar_region_95_start_length/mhc_start_lenth.csv\"\n",
    "    csv_data = pd.read_csv(mhc_start_length_path, low_memory = False)\n",
    "    csv_df = pd.DataFrame(csv_data)\n",
    "    arr_start=np.array(csv_df['start'])\n",
    "    arr_length=np.array(csv_df['length'])\n",
    "    mydic=dict()\n",
    "    midarr=[]\n",
    "    for i in range(len(arr_start)):\n",
    "        mydic[arr_start[i]]=arr_length[i]\n",
    "    for k,v in mydic.items():\n",
    "        if v>=51:\n",
    "            midarr.append(findPosition(filepath=\"../../mhcdataset/1kgp.29720000-33130000.vcf\",start=k,length=v))            \n",
    "        else:\n",
    "            continue\n",
    "    res[\"MHC\"]=midarr\n",
    "    return res\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath ../../split_chr13/xaa.vcf.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for '../../split_chr13/xaa.vcf.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath ../../split_chr1/xba.vcf.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for '../../split_chr1/xba.vcf.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath ../../split_chr1/xbb.vcf.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for '../../split_chr1/xbb.vcf.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath ../../split_chr2/xav.vcf.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for '../../split_chr2/xav.vcf.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath ../../split_chr3/xau.vcf.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for '../../split_chr3/xau.vcf.gz'\n"
     ]
    }
   ],
   "source": [
    "res=dict()\n",
    "mhcres=dict()\n",
    "for curDir, dirs, files in os.walk(top=\"/data2/wangxuedong/mhc_test_data/similar_region_95_start_length/\"):\n",
    "    for file in files:\n",
    "            filename=file[:file.index(\".\")]\n",
    "            if filename!=\"mhc_start_lenth\":\n",
    "                filepath=os.path.join(curDir,file)\n",
    "                GetPosition(filepath=filepath,res=res,threshold=51)\n",
    "            else:\n",
    "                getPositionforMHC(res=mhcres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'split_chr13_xaa': [[16000187, 18181463]],\n",
       " 'split_chr1_xba': [[121579777, 123992934]],\n",
       " 'split_chr1_xbb': [[123992935, 124938490]],\n",
       " 'split_chr2_xav': [[91720904, 94530414]],\n",
       " 'split_chr3_xau': [[90362505, 91477491]]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MHC': []}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhcres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
